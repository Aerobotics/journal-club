We develop a novel framework in this contest, which is distinguished from previous ones in three aspects: a new hybrid cascade architecture, a more intelligent anchoring scheme, and a new backbone network called FishNet. (1) We organize the entire pipeline with a hybrid cascade architecture, where branches for different tasks, including bounding box regression, mask prediction, and semantic segmentation, are organized in an interleaved way. This new architecture improves the information flow such that knowledges from different modules can be exchanged more effectively. (2) We develop a feature guided anchoring scheme instead of using dense and uniform anchors. This scheme predicts sparse anchors of arbitrary shapes, resulting in a significant performing gain of the RPN (AR raised by around 10%). (3) We incorporate a new backbone called FishNet in our ensemble, which can preserve and refine features of the same resolution from varying depths (accepted to NIPS 2018). The experiment settings are described as follows: we use COCO train2017 with bbox, mask and stuff annotations for training. We train five models with different backbone structures: SE-ResNeXt-154 (64*4d), ResNeXt-101 (64*4d), ResNeXt-101 (32*8d), DPN-107, and FishNet. The predictions from these networks are combined at the end. Here are some results on test-dev: (1) single model (single scale testing): 45.3 mask AP, (2) single model (multi-scale testing with flip): 47.4 mask AP, (3) ensemble of 5 models: 49.0 mask AP. We also develop *mm-detection*, a comprehensive and high performance object detection package based on PyTorch. During the COCO workshop, we are going to release this package, in order to promote the research in this area. References: [1] T. Lin, P. Dollár, R. B. Girshick, K. He, B. Hariharan, and S. J. Belongie. Feature pyramid networks for object detection. CVPR 2017. [2] K. He, G. Gkioxari, P. Dollár and R. B. Girshick. Mask R-CNN. ICCV 2017. [3] Z. Cai, N. Vasconcelos. Cascade R-CNN: Delving into High Quality Object Detection. CVPR 2018.